PMG開発メモの「モデルに関して」をもうちょっと真面目に書いたやつだと思ってください。
専門的にみれば、あるいはひょっとしたら専門的に見なくても間違ってるかもしれないけど許して。

## ハイパーパラメーター関連
大事だと思うやつと、それの調整方法に関して色々と。
#### 学習率
10^nで調節すればいいとか本には書いてあった。まあ割と重要なので、色々試して。
#### 最適化手法
AdamとかSGDとか。基本的にはAdamで問題ないと思うが、RMSpropとかも試す価値ありか？（元がWGANだし。）
#### alphaの変化のさせ方
基本小さい方がいいと思うが、それをすると、epochを増やさなくちゃいけなくなって、学習が遅れるので試行錯誤が必要か。
#### batch_size
5〜100ぐらいがベター？学習率が同じで、batch_sizeだけ減らすと、学習の回数が多くなるから学習が早く進むと思うが、その分過学習をおこしやすそうなのでケースバイケース。
#### 1個の解像度にかけるepoch数
当然多い方がいい。が、その分比例して時間が増えるので、スペックと相談して.......

## モデル関連
本来はモデルの構成とかもハイパーパラメーターに入るとか聞いたことがあるけど、分けた方がわかりやすいので。
モデルの変更すべきところに関して色々と。
#### 畳み込みの次元数
多分あげた方がいい。
generatorは

    b0=g_block(256,128),
    b1=g_block(128,64),
    b2=g_block(64,32),
    b3=g_block(32,16),
    b4=g_block(16,8),

となっているが、次のブロックの次元数が前のブロックの出力の次元数と合うようにすること。（最初と最後は多分なんでもokだけど、前後を調節する必要がある）

discriminatorは

    b0=d_block(65,64),
    b1=d_block(65,64),
    b2=d_block(65,64),
    b3=d_block(65,64),
    b4=d_block(65,64),

となっているが入力の次元数=出力の次元数+1となるように。また、全部同じ入力数と出力数じゃないと動かない。（これも最初と最後は多分なんでもokだけど、前後を調節する必要がある）

#### 論文との相違
論文では4\*4スタートだが、CGGでは16\*16スタート。タグ付けもあるしこのままでもいいかもしれないし、ダメかもしれない。お好みで変更して。

#### タグ付け
タグ付け機能は実装済みだけど、「これ本当に機能してんの？」って思ってる。正直タグ付きのGANを作る方法がこれであってるのかわからないので、論文漁るなりして頑張って

#### 抜本的に変える
今はPGGAN（もどき）だけど、当然他のGANのほうがいい可能性はあるし、VAEで画像生成後GANで超解像するっていう方法もありそう。
有力そうな手法を列挙しておく。

* LSGAN
* WGAN関連全般
* DRAGAN（本家の手法）
など

（他の手法も追記するかも）
